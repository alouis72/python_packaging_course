{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center class=\"mytitle\">\n",
    "**Python avancé**\n",
    "</center>\n",
    "\n",
    "# Les tests\n",
    "\n",
    "<center>\n",
    "<span>**Loic Gouarin**</span>\n",
    "</center>\n",
    "<center>\n",
    "<span>21 et 22 novembre 2017</span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pourquoi écrire des tests ?\n",
    "\n",
    "Lorsque l'on écrit un programme, il est généralement constitué de plusieurs fonctions que l'on assemble afin de décrire notre algorithme permettant de nous donner la réponse à notre problème. Un programme n'est pas forcément un développement sur un temps court. On voit beaucoup de librairies scientifiques qui ont plus de dix ans. Les fonctions peuvent donc être écrites à différents moments avec des échelles de temps bien différentes. On peut par exemple ajouter une fonctionnalité à un bout de code plusieurs années après en avoir écrit le coeur. Si il est primordial d'écrire de la documentation pour comprendre ce qui est fait, il est également judicieux d'écrire des tests pour s'assurer du bon fonctionnement de notre programme.\n",
    "\n",
    "Il faut noter que certains types de développement logiciel s'appuient sur les tests ([Test Driven Development](http://fr.wikipedia.org/wiki/Test_Driven_Development))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les types de tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On peut citer trois types de tests primordiaux permettant de s'assurer au mieux de l'absence de bugs dans notre programme. Un programme n'est jamais à 100% sûr.\n",
    "\n",
    "- les **tests unitaires** permettent de tester des fonctions ou des méthodes. \n",
    "\n",
    "- les **tests d'intégration** permettent de tester les interactions entre un petit nombre d'unités de programme.\n",
    "\n",
    "- les **tests du système complet** permettent de tester le programme dans sa globalité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Les tests sont donc écrits à des stades différents du développement mais ont chacun leur importance. \n",
    "\n",
    "Un seul de ces trois types de tests ne suffit pas pour tester l'intégrité du programme. \n",
    "\n",
    "Les tests unitaires et les tests d'intégration sont généralement testés avec les mêmes outils. \n",
    "\n",
    "Pour le dernier type de tests, on prendra des exemples concrets d'exécution et on testera la sortie avec une solution certifiée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notre cas d'étude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Nous allons calculer les coefficients de la suite de Fibonacci en utilisant les coefficients binomiaux. Les Coefficients binomiaux se calculent à partir de la formule suivante\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "n \\\\\n",
    "k\n",
    "\\end{array}\n",
    "\\right)=C_n^k=\\frac{n!}{k!(n-k)!} \\; \\text{pour} \\; k=0,\\cdots,n.\n",
    "$$\n",
    "\n",
    "On en déduit alors le calcul des coefficients de la suite de Fibonacci par la formule suivante\n",
    "\n",
    "$$\n",
    "\\sum_{k=0}^n\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "n-k \\\\\n",
    "k\n",
    "\\end{array} \n",
    "\\right)\n",
    "= F(n+1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Voici un exemple de code Python implantant cette formule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/fibonacci.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/fibonacci.py\n",
    "import numpy as np\n",
    "\n",
    "def factorielle(n):\n",
    "    \"\"\"\n",
    "    calcul de n!\n",
    "    \n",
    "    >>> factorielle(0)\n",
    "    1\n",
    "    >>> factorielle(5)\n",
    "    120\n",
    "    \n",
    "    \"\"\"\n",
    "    if n==1 or n==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n*factorielle(n-1)\n",
    "\n",
    "def somme(deb, fin, f, fargs=()):\n",
    "    \"\"\"\n",
    "    calcul de \n",
    "    \n",
    "    $$\n",
    "    \\sum_{k=deb}^fin f(k, *fargs)\n",
    "    $$\n",
    "    \n",
    "    test d'une suite arithmetique\n",
    "    >>> somme(0, 10, lambda k:k)\n",
    "    55.0\n",
    "    \n",
    "    test d'une suite geometrique\n",
    "    >>> somme(1, 8, lambda k: 2**k)\n",
    "    510.0\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    som = 0.\n",
    "    for k in range(deb, fin + 1):\n",
    "        som += f(k, *fargs)\n",
    "    return som\n",
    "    \n",
    "def coef_binomial(n, k):\n",
    "    \"\"\"\n",
    "    calcul de $C_n^k$\n",
    "    \n",
    "    >>> coef_binomial(4, 2)\n",
    "    6\n",
    "    \n",
    "    \"\"\"\n",
    "    if k > n or k < 0:\n",
    "        return 0.\n",
    "    return factorielle(n)//(factorielle(k)*factorielle(n-k))\n",
    "\n",
    "def fibonacci(n):\n",
    "    \"\"\"\n",
    "    Renvoie la liste des n premiers termes de la suite de Fibonacci\n",
    "    \n",
    "    >>> fibonacci(10)\n",
    "    [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\n",
    "    \n",
    "    \"\"\"\n",
    "    def g(k, n):\n",
    "        return coef_binomial(n - k, k)\n",
    "    \n",
    "    fibo = []\n",
    "    for i in range(n):\n",
    "        fibo.append(int(somme(0, i, g, fargs=(i,))))\n",
    "    \n",
    "    return fibo\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import doctest\n",
    "    doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On souhaite faire les tests suivants\n",
    "\n",
    "* **tests unitaires**: tester si les fonctions factorielle et somme fonctionnent correctement.\n",
    "* **tests d'intégration**: tester si les fonctions factorielle et somme fonctionnent correctement ensemble, tester si la fonction coef_binomial fonctionne correctement.\n",
    "* **tests du système complet**: tester si la fonction fibonacci donne le bon résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les outils de tests en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il existe différents outils en Python permettant de réaliser des tests ([https://wiki.python.org/moin/PythonTestingToolsTaxonomy](https://wiki.python.org/moin/PythonTestingToolsTaxonomy)). \n",
    "\n",
    "Nous nous intéresserons ici à trois d'entre eux\n",
    "\n",
    "- doctest\n",
    "- unittest\n",
    "- nose\n",
    "- pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "doctest permet de faire des tests basiques en s'appuyant sur les docstrings. Celles-ci permettent d'écrire de la documentation très facilement de nos fonctions ou de nos classes Python. Elles se placent tout de suite après une méthode, une fonction, une classe. On rappelle ici brièvement le principe en écrivant une documentation pour une fonction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`doctest` effectue\n",
    "\n",
    "* une recherche dans les sources des bouts de texte qui ressemblent à une session interactive Python,\n",
    "* une recherche dans des fichiers textes des bouts de texte qui ressemblent à une session interactive Python,\n",
    "* une exécution de ces bouts de session pour voir si le résultat est conforme.\n",
    "\n",
    "Les sessions interactives sont représentées par le symbole **>>>**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pour l'utiliser, il suffit d'importer le module `doctest` et d'appeler `testmod` si on veut tester l'ensemble d'un module comme dans notre exemple `fibonacci.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\r\n",
      "    coef_binomial(4, 2)\r\n",
      "Expecting:\r\n",
      "    6\r\n",
      "ok\r\n",
      "Trying:\r\n",
      "    factorielle(0)\r\n",
      "Expecting:\r\n",
      "    1\r\n",
      "ok\r\n",
      "Trying:\r\n",
      "    factorielle(5)\r\n",
      "Expecting:\r\n",
      "    120\r\n",
      "ok\r\n",
      "Trying:\r\n",
      "    fibonacci(10)\r\n",
      "Expecting:\r\n",
      "    [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\r\n",
      "ok\r\n",
      "Trying:\r\n",
      "    somme(0, 10, lambda k:k)\r\n",
      "Expecting:\r\n",
      "    55.0\r\n",
      "ok\r\n",
      "Trying:\r\n",
      "    somme(1, 8, lambda k: 2**k)\r\n",
      "Expecting:\r\n",
      "    510.0\r\n",
      "ok\r\n",
      "1 items had no tests:\r\n",
      "    __main__\r\n",
      "4 items passed all tests:\r\n",
      "   1 tests in __main__.coef_binomial\r\n",
      "   2 tests in __main__.factorielle\r\n",
      "   1 tests in __main__.fibonacci\r\n",
      "   2 tests in __main__.somme\r\n",
      "6 tests in 5 items.\r\n",
      "6 passed and 0 failed.\r\n",
      "Test passed.\r\n"
     ]
    }
   ],
   "source": [
    "! python examples/tests/fibonacci.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si `doctest` est très simple d'utilisation, on se rend bien compte qu'il est assez limité et qu'il ne permet pas de faire des tests très élaborés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ce module est également appelé PyUnit et reprend l'esprit de JUnit qui permet de faire des tests en java. \n",
    "\n",
    "Il supporte\n",
    "\n",
    "* les tests automatiques,\n",
    "* les fonctions d'initialisation et de finalisation pour chaque test,\n",
    "* l'aggrégation des tests,\n",
    "* l'indépendance des tests dans le rapport final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pour écrire des tests, il faut respecter certaines règles\n",
    "\n",
    "* Les tests doivent faire partie d'une classe héritée de la classe unittest.TestCase.\n",
    "* Les noms des méthodes de cette classe doivent avoir le prefixe test pour être considérés comme tests.\n",
    "* Les tests sont exécutés par ordre alphabétique.\n",
    "* La fonction exécutée avant chaque test doit avoir le nom setUp.\n",
    "* La fonction exécutée après chaque test doit avoir le nom tearDown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_fibo.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_fibo.py\n",
    "import unittest\n",
    "import sys\n",
    "sys.path.append(\"./examples/tests\")\n",
    "from fibonacci import *\n",
    "\n",
    "class TestFibo(unittest.TestCase):\n",
    "    def test_factorielle_0(self):\n",
    "        self.assertEqual(factorielle(0), 1)\n",
    "\n",
    "    def test_factorielle_5(self):\n",
    "        self.assertEqual(factorielle(5), 120)\n",
    "        \n",
    "    def test_somme(self):\n",
    "        self.assertEqual(somme(0, 10, lambda k:k), 55)\n",
    "\n",
    "    def test_coef_binomial(self):\n",
    "        self.assertEqual(coef_binomial(4, 2), 6)\n",
    "        \n",
    "    def test_fibo(self):\n",
    "        self.assertEqual(fibonacci(10), [1, 1, 2, 3, 5, 8, 13, 21, 34, 55])\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 5 tests in 0.001s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python examples/tests/test_fibo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- très simple à utiliser\n",
    "- multi plateforme\n",
    "- comprend `doctest` et `unittest`\n",
    "- modulaire\n",
    "- plein de plugins sont disponibles (par exemple [pep8](https://pypi.python.org/pypi/pytest-pep8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pep8-1.0.6\n",
      "collected 9 items                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/fibonacci.py::fibonacci.coef_binomial \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/fibonacci.py::fibonacci.factorielle \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/fibonacci.py::fibonacci.fibonacci \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/fibonacci.py::fibonacci.somme \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_fibo.py::TestFibo::test_coef_binomial \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_fibo.py::TestFibo::test_factorielle_0 \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_fibo.py::TestFibo::test_factorielle_5 \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_fibo.py::TestFibo::test_fibo \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_fibo.py::TestFibo::test_somme \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 9 passed in 0.11 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v --doctest-module examples/tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### assert\n",
    "\n",
    "Toutes les comparaisons dans `pytest` sont basées sur `assert`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_fibo.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_fibo.py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./examples/tests\")\n",
    "from fibonacci import *\n",
    "\n",
    "def test_factorielle_0():\n",
    "    assert factorielle(0) == 1\n",
    "    \n",
    "def test_factorielle_5():\n",
    "    assert factorielle(5) == 120\n",
    "        \n",
    "def test_somme():\n",
    "    assert somme(0, 10, lambda k:k) == 55\n",
    "\n",
    "def test_coef_binomial():\n",
    "    assert coef_binomial(4, 2) == 6\n",
    "        \n",
    "def test_fibo():\n",
    "    assert fibonacci(10) == [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pep8-1.0.6\n",
      "collected 5 items                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_fibo.py .....\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 5 passed in 0.09 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest examples/tests/test_fibo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `skip` et `skipif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_skip.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_skip.py\n",
    "\n",
    "import sys\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.skip(reason=\"doesn't work !!\")\n",
    "def test_skip():\n",
    "    assert True\n",
    "    \n",
    "@pytest.mark.skipif(sys.version_info < (3, 6), reason=\"Python version too old\")\n",
    "def test_skipif():\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pep8-1.0.6\n",
      "collected 2 items                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_skip.py::test_skip \u001b[33mSKIPPED\u001b[0m\n",
      "examples/tests/test_skip.py::test_skipif \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m===================== 1 passed, 1 skipped in 0.00 seconds ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_skip.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\r\n",
      "cachedir: .cache\r\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\r\n",
      "plugins: pep8-1.0.6\r\n",
      "\u001b[1m\r",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 2 items                                                              \u001b[0m\u001b[1m\r",
      "collected 2 items                                                               \u001b[0m\r\n",
      "\r\n",
      "examples/tests/test_skip.py::test_skip \u001b[33mSKIPPED\u001b[0m\r\n",
      "examples/tests/test_skip.py::test_skipif \u001b[32mPASSED\u001b[0m\r\n",
      "=========================== short test summary info ============================\r\n",
      "SKIP [1] examples/tests/test_skip.py:5: doesn't work !!\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m===================== 1 passed, 1 skipped in 0.00 seconds ======================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -rxs examples/tests/test_skip.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ajouter une marque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_mark.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_mark.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.slow\n",
    "def test_slow():\n",
    "    assert True\n",
    "    \n",
    "def test_not_slow():\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\r\n",
      "cachedir: .cache\r\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\r\n",
      "plugins: pep8-1.0.6\r\n",
      "\u001b[1m\r",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 2 items                                                              \u001b[0m\u001b[1m\r",
      "collected 2 items                                                               \u001b[0m\r\n",
      "\r\n",
      "examples/tests/test_mark.py::test_slow \u001b[32mPASSED\u001b[0m\r\n",
      "examples/tests/test_mark.py::test_not_slow \u001b[32mPASSED\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 2 passed in 0.01 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_mark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\r\n",
      "cachedir: .cache\r\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\r\n",
      "plugins: pep8-1.0.6\r\n",
      "\u001b[1m\r",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 2 items                                                              \u001b[0m\u001b[1m\r",
      "collected 2 items                                                               \u001b[0m\r\n",
      "\r\n",
      "examples/tests/test_mark.py::test_slow \u001b[32mPASSED\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m============================== 1 tests deselected ==============================\u001b[0m\r\n",
      "\u001b[32m\u001b[1m==================== 1 passed, 1 deselected in 0.00 seconds ====================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -m slow examples/tests/test_mark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\r\n",
      "cachedir: .cache\r\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\r\n",
      "plugins: pep8-1.0.6\r\n",
      "\u001b[1m\r",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 2 items                                                              \u001b[0m\u001b[1m\r",
      "collected 2 items                                                               \u001b[0m\r\n",
      "\r\n",
      "examples/tests/test_mark.py::test_not_slow \u001b[32mPASSED\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m============================== 1 tests deselected ==============================\u001b[0m\r\n",
      "\u001b[32m\u001b[1m==================== 1 passed, 1 deselected in 0.00 seconds ====================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -m \"not slow\" examples/tests/test_mark.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Capture de la sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing examples/tests/test_capture.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_capture.py\n",
    "\n",
    "def test_capture():\n",
    "    print(\"coucou\")\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\r\n",
      "cachedir: .cache\r\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\r\n",
      "plugins: pep8-1.0.6\r\n",
      "\u001b[1m\r",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 1 item                                                               \u001b[0m\u001b[1m\r",
      "collected 1 item                                                                \u001b[0m\r\n",
      "\r\n",
      "examples/tests/test_capture.py::test_capture \u001b[32mPASSED\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.00 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_capture.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\r\n",
      "cachedir: .cache\r\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\r\n",
      "plugins: pep8-1.0.6\r\n",
      "\u001b[1m\r",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 1 item                                                               \u001b[0m\u001b[1m\r",
      "collected 1 item                                                                \u001b[0m\r\n",
      "\r\n",
      "examples/tests/test_capture.py::test_capture coucou\r\n",
      "\u001b[32mPASSED\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.00 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -s examples/tests/test_capture.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exécuter les tests par mots clés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing examples/tests/test_key.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_key.py\n",
    "\n",
    "def test_foo_1():\n",
    "    assert True\n",
    "    \n",
    "def test_foo_2():\n",
    "    assert True\n",
    "    \n",
    "def test_bar_1():\n",
    "    assert True\n",
    "    \n",
    "def test_bar_2():\n",
    "    assert True\n",
    "\n",
    "def test_bar_3():\n",
    "    assert True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\r\n",
      "cachedir: .cache\r\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\r\n",
      "plugins: pep8-1.0.6\r\n",
      "\u001b[1m\r",
      "collecting 0 items                                                              \u001b[0m\u001b[1m\r",
      "collecting 5 items                                                              \u001b[0m\u001b[1m\r",
      "collected 5 items                                                               \u001b[0m\r\n",
      "\r\n",
      "examples/tests/test_key.py::test_foo_1 \u001b[32mPASSED\u001b[0m\r\n",
      "examples/tests/test_key.py::test_foo_2 \u001b[32mPASSED\u001b[0m\r\n",
      "\r\n",
      "\u001b[1m============================== 3 tests deselected ==============================\u001b[0m\r\n",
      "\u001b[32m\u001b[1m==================== 2 passed, 3 deselected in 0.01 seconds ====================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -k foo examples/tests/test_key.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pep8-1.0.6\n",
      "collected 5 items                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_key.py::test_bar_1 \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_key.py::test_bar_2 \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_key.py::test_bar_3 \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[1m============================== 2 tests deselected ==============================\u001b[0m\n",
      "\u001b[32m\u001b[1m==================== 3 passed, 2 deselected in 0.01 seconds ====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -k bar examples/tests/test_key.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pep8-1.0.6\n",
      "collected 5 items                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_key.py::test_foo_1 \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_key.py::test_foo_2 \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[1m============================== 3 tests deselected ==============================\u001b[0m\n",
      "\u001b[32m\u001b[1m==================== 2 passed, 3 deselected in 0.01 seconds ====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v -k \"not bar\" examples/tests/test_key.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `fixture`\n",
    "\n",
    "- Permet de spécifier plus facilement ce qu'il faut faire avant et après un test.\n",
    "- Peux s'appliquer à une fonction, une classe, un module ou tout le projet.\n",
    "- Une `fixture` peut appeler une autre `fixture`.\n",
    "- Une `fixture` est appelée par son nom par le test qui en a besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_fixture_1.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_fixture_1.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture()\n",
    "def tmpfile():\n",
    "    with open(\"tmp_fixture.txt\", \"w\") as f:\n",
    "        yield f\n",
    "\n",
    "def test_file(tmpfile):\n",
    "    tmpfile.write(\"temporary file : \" + tmpfile.name)\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pep8-1.0.6\n",
      "collected 1 item                                                                \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_fixture_1.py::test_file \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.01 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_fixture_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary file : tmp_fixture.txt"
     ]
    }
   ],
   "source": [
    "! cat tmp_fixture.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `parametrize`\n",
    "\n",
    "Il est également possible de définir un ensemble de paramètres à tester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing examples/tests/test_parametrize_1.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_parametrize_1.py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./examples/tests\")\n",
    "import pytest\n",
    "\n",
    "from fibonacci import *\n",
    "\n",
    "@pytest.mark.parametrize('fact_number, expected', [\n",
    "    (0, 1),\n",
    "    (1, 1),\n",
    "    (2, 2),\n",
    "    (3, 6),\n",
    "    (4, 24),\n",
    "    (5, 120)\n",
    "])\n",
    "def test_methods(fact_number, expected):\n",
    "    assert factorielle(fact_number) == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pylint-0.7.1, pep8-1.0.6, cov-2.5.1\n",
      "collected 6 items                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_parametrize_1.py::test_methods[0-1] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[1-1] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[2-2] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[3-6] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[4-24] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_1.py::test_methods[5-120] \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 6 passed in 0.08 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_parametrize_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_parametrize_2.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_parametrize_2.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "from fibonacci import *\n",
    "\n",
    "@pytest.mark.parametrize('value1', range(5))\n",
    "@pytest.mark.parametrize('value2', range(0,10,2))  \n",
    "def test_methods(value1, value2):\n",
    "    assert not (value1*value2 & 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pylint-0.7.1, pep8-1.0.6, cov-2.5.1\n",
      "collected 25 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-0] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-1] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-2] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-3] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[0-4] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-0] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-1] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-2] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-3] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[2-4] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-0] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-1] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-2] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-3] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[4-4] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-0] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-1] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-2] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-3] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[6-4] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-0] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-1] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-2] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-3] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_parametrize_2.py::test_methods[8-4] \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m========================== 25 passed in 0.12 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_parametrize_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `approx`\n",
    "\n",
    "Il est souvent utile de comparer les valeurs d'un calcul numérique en s'assurant qu'elles sont proches des valeurs attendues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_approx_1.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_approx_1.py\n",
    "\n",
    "from pytest import approx\n",
    "\n",
    "def test_approx_1():\n",
    "    assert 1.001 == approx(1)\n",
    "    \n",
    "def test_approx_2():\n",
    "    assert 1.001 == approx(1, rel=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pylint-0.7.1, pep8-1.0.6, cov-2.5.1\n",
      "collected 2 items                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_approx_1.py::test_approx_1 \u001b[31mFAILED\u001b[0m\n",
      "examples/tests/test_approx_1.py::test_approx_2 \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ test_approx_1 _________________________________\u001b[0m\n",
      "\n",
      "\u001b[1m    def test_approx_1():\u001b[0m\n",
      "\u001b[1m>       assert 1.001 == approx(1)\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 1.001 == 1 ± 1.0e-06\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 1 ± 1.0e-06 = approx(1)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mexamples/tests/test_approx_1.py\u001b[0m:5: AssertionError\n",
      "\u001b[31m\u001b[1m====================== 1 failed, 1 passed in 0.05 seconds ======================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_approx_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting examples/tests/test_approx_2.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_approx_2.py\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "from pytest import approx\n",
    "\n",
    "def ones_array(shape):\n",
    "    return np.ones(shape)\n",
    "\n",
    "@pytest.fixture(params=[5, (3,2), (5, 4, 3)])\n",
    "def init_array(request):\n",
    "    return ones_array(request.param)\n",
    "    \n",
    "def test_approx(init_array):\n",
    "    shape = init_array.shape\n",
    "    random_array = 1 + 1e-5*np.random.random(shape)\n",
    "    assert random_array == approx(init_array, rel=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pylint-0.7.1, pep8-1.0.6, cov-2.5.1\n",
      "collected 3 items                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_approx_2.py::test_approx[init_array0] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_approx_2.py::test_approx[5] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_approx_2.py::test_approx[init_array2] \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 3 passed in 0.08 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_approx_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing examples/tests/test_approx_id_2.py\n"
     ]
    }
   ],
   "source": [
    "%%file examples/tests/test_approx_id_2.py\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "from pytest import approx\n",
    "\n",
    "def ones_array(shape):\n",
    "    return np.ones(shape)\n",
    "\n",
    "@pytest.fixture(params=[5, (3,2), (5, 4, 3)], \n",
    "                ids=['1d', '2d', '3d'])\n",
    "def init_array(request):\n",
    "    return ones_array(request.param)\n",
    "    \n",
    "def test_approx(init_array):\n",
    "    shape = init_array.shape\n",
    "    random_array = 1 + 1e-5*np.random.random(shape)\n",
    "    assert random_array == approx(init_array, rel=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.2, pytest-3.2.3, py-1.4.34, pluggy-0.4.0 -- /home/loic/miniconda3/envs/python3.6/bin/python\n",
      "cachedir: .cache\n",
      "rootdir: /home/loic/Formations/2017/python/cnrs, inifile:\n",
      "plugins: pylint-0.7.1, pep8-1.0.6, cov-2.5.1\n",
      "collected 3 items                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "examples/tests/test_approx_id_2.py::test_approx[1d] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_approx_id_2.py::test_approx[2d] \u001b[32mPASSED\u001b[0m\n",
      "examples/tests/test_approx_id_2.py::test_approx[3d] \u001b[32mPASSED\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 3 passed in 0.07 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v examples/tests/test_approx_id_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Références\n",
    "\n",
    "- [La documentation de Pytest](https://docs.pytest.org)\n",
    "- [Pytest 3.0](https://www.youtube.com/watch?v=HPUg31eylds)\n",
    "- [Pytest à PyCon2016](https://speakerdeck.com/pycon2016/michael-tom-wing-christie-wilson-introduction-to-unit-testing-in-python-with-pytest)\n",
    "- [Quatres petits tutos](https://www.youtube.com/watch?v=l32bsaIDoWk&list=PLeo1K3hjS3utzQYDNRNluzqJqpMXx6hHu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "link:\n",
    "\n",
    "https://speakerdeck.com/pycon2016/michael-tom-wing-christie-wilson-introduction-to-unit-testing-in-python-with-pytest\n",
    "\n",
    "https://www.youtube.com/watch?v=nznkU7Em5ns\n",
    "\n",
    "http://il.pycon.org/2016/static/sessions/eli-gur-pytest.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import \"./style/reveal.css\";\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute this part to modify the css style\\n\",\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./style/custom.css\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "livereveal": {
   "autolaunch": true,
   "scroll": true,
   "width": "80%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
